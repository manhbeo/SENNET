{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNq_TG6Wyokb",
        "outputId": "db5d5615-a24f-4383-a741-fb6576a227f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6YtLezZ1PZ3"
      },
      "outputs": [],
      "source": [
        "# !cd drive/My\\ Drive/Colab\\ Notebooks\n",
        "# !pip install -q kaggle\n",
        "# !mkdir -p ~/.kaggle\n",
        "# !cp drive/My\\ Drive/Colab\\ Notebooks/kaggle.json ~/.kaggle/\n",
        "# !chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DFwUGJnv1v35"
      },
      "outputs": [],
      "source": [
        "# !cd drive/My\\ Drive/Colab\\ Notebooks\n",
        "# !kaggle competitions download -c blood-vessel-segmentation --force"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nFhdhCFb5bXq"
      },
      "outputs": [],
      "source": [
        "# !unzip blood-vessel-segmentation.zip -d drive/My\\ Drive/Colab\\ Notebooks/sennet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvXgjNPcx-vI",
        "outputId": "5177b221-099a-46da-b511-e34e3fb79a63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting livelossplot\n",
            "  Downloading livelossplot-0.5.5-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from livelossplot) (3.7.1)\n",
            "Requirement already satisfied: bokeh in /usr/local/lib/python3.10/dist-packages (from livelossplot) (3.3.3)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (3.1.3)\n",
            "Requirement already satisfied: contourpy>=1 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (1.23.5)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (23.2)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (1.5.3)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (9.4.0)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (6.0.1)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (6.3.2)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (2023.10.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->livelossplot) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->livelossplot) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->livelossplot) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->livelossplot) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->livelossplot) (2.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.9->bokeh->livelossplot) (2.1.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->bokeh->livelossplot) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->livelossplot) (1.16.0)\n",
            "Installing collected packages: livelossplot\n",
            "Successfully installed livelossplot-0.5.5\n"
          ]
        }
      ],
      "source": [
        "!pip install livelossplot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ogxqT3b-x-vJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, ReLU\n",
        "from livelossplot.tf_keras import PlotLossesCallback\n",
        "from tensorflow.keras.models import save_model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from math import log2, floor, ceil\n",
        "\n",
        "#(1706, 1510)\n",
        "#(1041, 1511)\n",
        "#(1303, 912)\n",
        "#(1928, 1928)\n",
        "#(1303, 912)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fTEz6Wuqx-vM"
      },
      "outputs": [],
      "source": [
        "#label is output (image -> label)\n",
        "\n",
        "# use U-net\n",
        "\n",
        "# to vừa phải, to quá sẽ overfit\n",
        "def conv_block(inputs, filters):\n",
        "    x = tf.keras.layers.Conv2D(filters, 3, padding='same')(inputs)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "    #x = tf.keras.layers.Dropout(0.5)(x)    #deal with vanishing grad (maybe work?)\n",
        "    x = tf.keras.layers.Conv2D(filters, 3, padding='same')(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    return x\n",
        "\n",
        "def downsample_block(inputs, filters):\n",
        "    x = conv_block(inputs, filters)\n",
        "    p = tf.keras.layers.MaxPooling2D(2)(x)\n",
        "    return x, p\n",
        "\n",
        "def upsample_block(inputs, skip, filters):\n",
        "    us = tf.keras.layers.Conv2DTranspose(filters, 2, strides=2, padding='same')(inputs)\n",
        "    concat = tf.keras.layers.Concatenate()([us, skip])\n",
        "    x = conv_block(concat, filters)\n",
        "    return x\n",
        "\n",
        "def unet(input_shape):\n",
        "    inputs = tf.keras.layers.Input(input_shape)\n",
        "\n",
        "    # Encoder\n",
        "    enc1, pool1 = downsample_block(inputs, 64)\n",
        "    enc2, pool2 = downsample_block(pool1, 128)\n",
        "    enc3, pool3 = downsample_block(pool2, 256)\n",
        "    enc4, pool4 = downsample_block(pool3, 512)\n",
        "    #enc5, pool5 = downsample_block(pool4, 1024)\n",
        "    #enc6, pool6 = downsample_block(pool5, 2048)\n",
        "\n",
        "    # Bottleneck\n",
        "    bottleneck = conv_block(pool4, 1024)\n",
        "\n",
        "    # Decoder\n",
        "    #dec6 = upsample_block(bottleneck, enc6, 2048)\n",
        "    #dec5 = upsample_block(bottleneck, enc5, 1024)\n",
        "    dec4 = upsample_block(bottleneck, enc4, 512)\n",
        "    dec3 = upsample_block(dec4, enc3, 256)\n",
        "    dec2 = upsample_block(dec3, enc2, 128)\n",
        "    dec1 = upsample_block(dec2, enc1, 64)\n",
        "\n",
        "    outputs = tf.keras.layers.Conv2D(1, 1, activation='sigmoid')(dec1)\n",
        "\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89KoQzFHcJMo"
      },
      "outputs": [],
      "source": [
        "model = unet((None, None, 1))\n",
        "# can use some other loss func (dice loss)\n",
        "# use histogram to manage gradient\n",
        "optimizer = tf.keras.optimizers.Adam(0.0006)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ejPr3UkVJ7v"
      },
      "outputs": [],
      "source": [
        "# cur_dir = \"/content/drive/MyDrive/Colab Notebooks/sennet/train/kidney_1_voi\"\n",
        "# label_dir = os.path.join(cur_dir, \"labels\")\n",
        "\n",
        "# label = cv2.imread(os.path.join(label_dir, \"0000.tif\"), cv2.IMREAD_UNCHANGED)\n",
        "# print(label.shape)\n",
        "# new_shape = tuple(ceil(k/16) for k in label.shape)\n",
        "# target_height = new_shape[0]*16\n",
        "# target_width = new_shape[1]*16\n",
        "# print(new_shape)\n",
        "# offset_height = (target_height - label.shape[0]) // 2\n",
        "# offset_width = (target_width - label.shape[1]) // 2\n",
        "\n",
        "# label_tf = tf.expand_dims(tf.convert_to_tensor(label, dtype=tf.float32), axis=-1)\n",
        "# label = tf.image.pad_to_bounding_box(\n",
        "#     label_tf, offset_height, offset_width, target_height, target_width\n",
        "# )\n",
        "\n",
        "# print(label.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jr4tISM3x-vM",
        "outputId": "384d8d96-eca8-4284-a48e-af9a34bee251"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Read: /content/drive/MyDrive/Colab Notebooks/sennet/train/kidney_1_dense\n",
            "Epoch 1/20\n"
          ]
        }
      ],
      "source": [
        "#add early stop\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1) #, start_from_epoch = 5) #val_accuracy makes train accuracy low\n",
        "#reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.00002)\n",
        "\n",
        "#read .tiff files\n",
        "#the image is too large. Considering running just a small set of image each time\n",
        "\n",
        "# if os.path.exists(\"/content/drive/MyDrive/Colab Notebooks/sennet/uNet.keras\"):\n",
        "#   model.load_weights(\"/content/drive/MyDrive/Colab Notebooks/sennet/uNet.keras\")\n",
        "\n",
        "#TODO: after each dir, load weight and run model\n",
        "#TODO: code chọn random 100 img cùng size mỗi lần để chạy\n",
        "#will the number of parameter change? no\n",
        "# do we need to crop?\n",
        "\n",
        "dirs = os.listdir(\"/content/drive/MyDrive/Colab Notebooks/sennet/train\")\n",
        "np.random.shuffle(dirs)\n",
        "\n",
        "trained_imgs = {}\n",
        "for dir in dirs:\n",
        "  trained_imgs[dir] = []\n",
        "# why dont add all img here and then remove?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#TODO: remove dir in dirs when traing all the image inside\n",
        "\n",
        "# for dirname in os.listdir(\"/content/drive/MyDrive/Colab Notebooks/sennet/train\"):\n",
        "#     cur_dir = os.path.join(\"/content/drive/MyDrive/Colab Notebooks/sennet/train\", dirname)\n",
        "#     X = []\n",
        "#     Y = []\n",
        "#     i = 0\n",
        "\n",
        "while len(dirs) > 0:\n",
        "  chosen_dir = dirs[randint(0, len(dirs) - 1)]\n",
        "  cur_dir = os.path.join(\"/content/drive/MyDrive/Colab Notebooks/sennet/train\", chosen_dir)\n",
        "\n",
        "  imgs = os.listdir(os.path.join(cur_dir, \"labels\"))\n",
        "  np.random.shuffle(imgs)\n",
        "\n",
        "  while i < len(imgs):\n",
        "    X = []\n",
        "    Y = []\n",
        "    for k in range (0, 100): #5 for testing, change when run\n",
        "    # smaller is more prone to overfit\n",
        "      if i >= len(imgs): break\n",
        "      label_dir = os.path.join(cur_dir, \"labels\")\n",
        "      label = cv2.imread(os.path.join(label_dir, imgs[i]), cv2.IMREAD_UNCHANGED)\n",
        "\n",
        "      if cur_dir == \"/content/drive/MyDrive/Colab Notebooks/sennet/train/kidney_3_dense\":\n",
        "          img_dir = \"/content/drive/MyDrive/Colab Notebooks/sennet/train/kidney_3_sparse/images\"\n",
        "      else:\n",
        "          img_dir = os.path.join(cur_dir, \"images\")\n",
        "\n",
        "      img = cv2.imread(os.path.join(img_dir, imgs[i]), cv2.IMREAD_UNCHANGED)\n",
        "      img = (img - img.min()) / (img.max() - img.min())\n",
        "\n",
        "      new_shape = tuple(ceil(k/64) for k in img.shape)\n",
        "      target_height = new_shape[0]*64\n",
        "      target_width = new_shape[1]*64\n",
        "      #print(new_shape)\n",
        "      offset_height = (target_height - label.shape[0]) // 2\n",
        "      offset_width = (target_width - label.shape[1]) // 2\n",
        "\n",
        "      img_tf = tf.expand_dims(tf.convert_to_tensor(img, dtype=tf.float32), axis=-1)\n",
        "      label_tf = tf.expand_dims(tf.convert_to_tensor(label, dtype=tf.float32), axis=-1) / 255\n",
        "      img = tf.image.pad_to_bounding_box(img_tf, offset_height, offset_width, target_height, target_width)\n",
        "      label = tf.image.pad_to_bounding_box(label_tf, offset_height, offset_width, target_height, target_width)\n",
        "      X.append(img)\n",
        "      Y.append(label)\n",
        "\n",
        "\n",
        "      #flip\n",
        "      # img = tf.image.flip_left_right(img)\n",
        "      # label = tf.image.flip_left_right(label)\n",
        "      # X.append(img)\n",
        "      # Y.append(label)\n",
        "\n",
        "      # img = tf.image.flip_up_down(img)\n",
        "      # label = tf.image.flip_up_down(label)\n",
        "      # X.append(img)\n",
        "      # Y.append(label)\n",
        "\n",
        "      i += 1\n",
        "\n",
        "    #optimizer.learning_rate.assign(0.0008)\n",
        "    callbacks = [PlotLossesCallback(), early_stopping]#, reduce_lr]\n",
        "    #dont have cross val yet\n",
        "    model.fit(\n",
        "        np.array(X), np.array(Y),\n",
        "        validation_split=.2,\n",
        "        batch_size=5,     #change this\n",
        "        epochs=20,       #change this\n",
        "        verbose=1,\n",
        "        callbacks=callbacks\n",
        "    )\n",
        "\n",
        "    print(\"Train on: \" + cur_dir + \", i = \" + str(i))\n",
        "    file1 = open('/content/drive/MyDrive/Colab Notebooks/sennet/train.txt', 'a')\n",
        "    file1.write(\"Train on: \" + cur_dir + \", i = \" + str(i) + \"\\n\")\n",
        "    file1.close()\n",
        "\n",
        "  #TODO: save parameter\n",
        "  save_model(model, \"/content/drive/MyDrive/Colab Notebooks/sennet/uNet.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Low validation accuracy - high training accuracy: overfit\n",
        "# Validation loss increase: overfit\n",
        "# low training accuracy - high validation accuracy: underfit\n",
        "# 0 nên dùng model quá to (overfit)"
      ],
      "metadata": {
        "id": "6WVQZIzdgKCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GFPLvP0zD6A5"
      },
      "outputs": [],
      "source": [
        "#output is image, so very much likely to underfit (apply for img seg?)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "slX2H_F-vGVX"
      },
      "outputs": [],
      "source": [
        "#save test img to an array\n",
        "#change test size to 2048, then after predict crop and change to rle\n",
        "#TODO: write this\n",
        "test = []\n",
        "for dirname in os.listdir(\"/content/drive/MyDrive/Colab Notebooks/sennet/test\"):\n",
        "  cur_dir = os.path.join(\"/content/drive/MyDrive/Colab Notebooks/sennet/test\", dirname)\n",
        "  print(\"Read: \" + cur_dir)\n",
        "\n",
        "  X = []\n",
        "  Y = []\n",
        "  i = 0\n",
        "  dirs = os.listdir(os.path.join(cur_dir, \"labels\"))\n",
        "\n",
        "  for k in range (0, 5): #5 for testing, increase when run\n",
        "    if i >= len(dirs): break\n",
        "    label_dir = os.path.join(cur_dir, \"labels\")\n",
        "    label = cv2.imread(os.path.join(label_dir, dirs[i]), cv2.IMREAD_UNCHANGED)\n",
        "\n",
        "    if cur_dir == \"/content/drive/MyDrive/Colab Notebooks/sennet/train/kidney_3_dense\":\n",
        "        img_dir = \"/content/drive/MyDrive/Colab Notebooks/sennet/train/kidney_3_sparse/images\"\n",
        "        img = cv2.imread(os.path.join(img_dir, dirs[i]), cv2.IMREAD_UNCHANGED)\n",
        "    else:\n",
        "        img_dir = os.path.join(cur_dir, \"images\")\n",
        "        img = cv2.imread(os.path.join(img_dir, dirs[i]), cv2.IMREAD_UNCHANGED)\n",
        "\n",
        "    img_tf = tf.expand_dims(tf.convert_to_tensor(img, dtype=tf.float32), axis=-1)\n",
        "    label_tf = tf.expand_dims(tf.convert_to_tensor(label, dtype=tf.float32), axis=-1)\n",
        "    # img_tf.shape  #return a tuple, use 'for' to access.\n",
        "    # shape is same for each dir, so calculate new dim at the beginning of the for loop\n",
        "    #/2 3 lần (/8), chỉ cần làm tròn lên. Nhưng liệu có to quá?\n",
        "    img = tf.image.resize_with_pad(img_tf, 512, 512)\n",
        "    label = tf.image.resize_with_pad(label_tf, 512, 512)\n",
        "    X.append(img)\n",
        "    Y.append(label)\n",
        "    i += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UAguhZKby03W"
      },
      "outputs": [],
      "source": [
        "#predict test data\n",
        "p = model.predict(np.array())"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "A100"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "databundleVersionId": 6962461,
          "sourceId": 61446,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30626,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}